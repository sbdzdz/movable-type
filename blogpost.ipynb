{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prologue: In Which the Author Explains Why He's Doing What He's Doing\n",
    "\n",
    "Books are fun. <sup>[[citation needed](https://xkcd.com/285)]</sup> \n",
    "\n",
    "What's even more fun are vector space models, clustering algorithms, and dimensionality reduction techniques. In this blog post, we're going to combine it all by playing around with a small set of texts from project Gutenberg. With a bit of luck, Python, and lots of trial and error, we might just learn something interesting.\n",
    "\n",
    "### Chapter One: In Which Books are Fetched and Puns are Made\n",
    "We should start by fetching some books. There are many ways to do it, but for starters let's just use what NLTK has to offer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "titles = gutenberg.fileids()\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This rather eclectic collection will serve as our dataset. How about we weed out some boring books and get the full text for the rest (your definition of boring may vary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "boring = {'bible-kjv.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt'} \n",
    "titles = [t for t in titles if t not in boring] \n",
    "texts = [gutenberg.raw(t) for t in titles]\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conveniently (and completely coincidentally) the remaining titles fall into five categories I spent far too much time naming:\n",
    "- Novel and Novelty: `emma`, `persuasion`, `sense` \n",
    "- Bard's Tales: `caesar`, `macbeth`, `hamlet`\n",
    "- Chestertomes: `ball`, `brown`, `thursday`\n",
    "- BMW (Blake, Milton, Whitman): `poems`, `paradise`, `leaves`\n",
    "- BBC (Bryant, Burgess, Carroll): `stories`, `buster`, `alice`\n",
    "\n",
    "In other words, our modest library contains three Jane Austen's novels, three Shakespeare's plays, three novels by Gilbert K. Chesterton, three poem collections, and three children books (I'm sorry, Mr. Carroll). Let's find out if this classification is equally intuitive to a machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter Two: In which Books are Turned into Numbers and What Happens Then\n",
    "There is a couple of ways we could represent a collection of documents as a set of numerical vectors. We're going to use a tf-idf matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(texts, max_df=.5, min_df=1, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TfidfVectorizer` does all the work for us – it filters stop words, normalizes every row of the tf-idf matrix, and even lets us impose constraints on the maximal value of document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austen-emma.txt: emma\n",
      "austen-persuasion.txt: anne\n",
      "austen-sense.txt: elinor\n",
      "blake-poems.txt: weep\n",
      "bryant-stories.txt: jackal\n",
      "burgess-busterbrown.txt: buster\n",
      "carroll-alice.txt: alice\n",
      "chesterton-ball.txt: turnbull\n",
      "chesterton-brown.txt: flambeau\n",
      "chesterton-thursday.txt: syme\n",
      "milton-paradise.txt: hath\n",
      "shakespeare-caesar.txt: bru\n",
      "shakespeare-hamlet.txt: ham\n",
      "shakespeare-macbeth.txt: macb\n",
      "whitman-leaves.txt: states\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "maxmatrix = np.argmax(tfidf_matrix.toarray(), axis=1)\n",
    "for index, title in enumerate(titles):\n",
    "    print(\"{}: {}\".format(title, terms[maxmatrix[index]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
